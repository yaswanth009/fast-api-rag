# fastapi-vibe-coding

This repo demonstrates a FastAPI application with Retrieval-Augmented Generation (RAG) using Milvus Managed (Zilliz Cloud) and OpenAI embeddings, now with hybrid RAG+ChatGPT answering.

## Features

- **RAG-powered Q&A with ChatGPT**: Ask questions about uploaded documents or manually added text, and get answers generated by OpenAI ChatGPT, grounded in the most relevant content from your data.
- **Milvus Managed (Zilliz Cloud) Integration**: Stores document chunks and embeddings for fast semantic search.
- **OpenAI Embeddings**: Uses `text-embedding-ada-002` for vectorization.
- **Manual Text Addition**: Add text directly to RAG via API.
- **Return problem.txt**: Fetch the contents of `problem.txt` via API.

## Endpoints

### 1. Upload Document for RAG
`POST /upload-document`
- Upload a PDF, DOCX, or TXT file.
- The document is chunked, embedded, and stored in Milvus for RAG.

### 2. Add Document String Manually
`POST /add-document-string`
- Add a string as a document for RAG.
- **Body:**
  ```json
  {
    "text": "Your text here...",
    "document_name": "OptionalName"
  }
  ```

### 3. Ask a Question (RAG + ChatGPT)
`POST /ask`
- Ask a question about the uploaded or added documents.
- The backend retrieves the most relevant context from Milvus, then sends both the context and your question to OpenAI ChatGPT (gpt-3.5-turbo) to generate a grounded answer.
- If no relevant context is found, ChatGPT answers as best it can.
- **Body:**
  ```json
  {
    "message": "Your question here..."
  }
  ```

### 4. Get problem.txt
`GET /get-problem`
- Returns the contents of `problem.txt` as JSON:
  ```json
  { "content": "...file contents..." }
  ```

## Requirements
- Python 3.8+
- Milvus Managed (Zilliz Cloud) account and collection
- OpenAI API key

## Setup
1. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```
2. **Set up Milvus Managed (Zilliz Cloud):**
   - Update `MILVUS_URI`, `MILVUS_TOKEN`, `COLLECTION_NAME`, and `DIMENSION` in `main.py` as needed.
   - The collection dimension must match the embedding size (3270 if padded, 1536 for OpenAI Ada by default).
3. **Set your OpenAI API key:**
   ```bash
   export OPENAI_API_KEY=sk-...
   ```
4. **Run the app:**
   ```bash
   uvicorn main:app --reload
   ```

## Example Usage

**Add a document string:**
```bash
curl -X POST http://localhost:8000/add-document-string \
  -H "Content-Type: application/json" \
  -d '{"text": "This is my manual document string.", "document_name": "TestDoc"}'
```

**Ask a question (RAG+ChatGPT):**
```bash
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"message": "What is this document about?"}'
```

**Get problem.txt:**
```bash
curl http://localhost:8000/get-problem
```

---

### Hybrid RAG + LLM Approach
- The `/ask` endpoint first retrieves relevant context from your data using Milvus (RAG).
- It then sends both the context and your question to OpenAI ChatGPT, which generates a natural, context-grounded answer.
- If no context is found, ChatGPT answers as best it can.

For more details, see the code and endpoint docstrings.
